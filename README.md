
# Next Word Prediction Using LSTM

This project builds a text generation model that predicts the next word based on input sequences.
It uses Long Short-Term Memory (LSTM) networks and is trained on the WikiText-2 dataset ideal for natural language generation tasks.

Deployed using Streamlit for real-time interaction.


## Screenshots

![Image](https://github.com/user-attachments/assets/a6531534-7eeb-4bee-8bec-e0cf45f4e31b)


## Deployment

To deploy this project run

```bash
  https://next-word-prediction-using-lstm-diwan.streamlit.app/
```


## Features

- Text preprocessing (tokenization, padding, sequence creation)
- LSTM-based sequence modeling with embedding layer
- EarlyStopping to prevent overfitting
- Interactive real-time predictions with Streamlit


## Tech Stack

Python

TensorFlow / Keras

NumPy, Pandas

Streamlit (for deployment)

WikiText-2 (dataset)


## ðŸ”— Links
[![portfolio](https://img.shields.io/badge/my_portfolio-000?style=for-the-badge&logo=ko-fi&logoColor=white)](https://diwansinghchauhan.github.io/portfolio/)
[![linkedin](https://img.shields.io/badge/linkedin-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/diwansinghchauhan/)
